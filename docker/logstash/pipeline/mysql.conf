#logstash输入配置
input {
  #jdbc输入配置，用来指定mysql中需要同步的数据查询SQL及同步周期
  jdbc {
    jdbc_driver_library => "/usr/share/logstash/mysql-connector-java.jar"
    jdbc_driver_class => "com.mysql.jdbc.Driver"
    jdbc_connection_string => "jdbc:mysql://sg-mysql:3306/es_db"
    jdbc_user => "root"
    jdbc_password => "root"
    # 是否开启分页
    jdbc_paging_enabled => true
     # 是否开启记录上次追踪的结果，也就是上次更新的时间，这个会记录到 last_run_metadata_path 的文件
    use_column_value => true
    # 用来控制增量更新的字段，一般是自增id或者创建、更新时间，注意这里要采用sql语句中select采用的字段别名
    tracking_column => "unix_ts_in_secs"
    # tracking_column 对应字段的类型
    tracking_column_type => "numeric"
    # 设置定时任务间隔  含义：分、时、天、月、年，全部为*默认含义为每分钟跑一次任务，这里设置为每5分钟同步一次
    schedule => "*/5 * * * * *"
     # 同步数据的查询sql语句
    statement => "SELECT *, UNIX_TIMESTAMP(modification_time) AS unix_ts_in_secs FROM es_table WHERE (UNIX_TIMESTAMP(modification_time) > :sql_last_value AND modification_time < NOW()) ORDER BY modification_time ASC"
  }
}
#logstash输入数据的字段匹配和数据过滤
filter {
  mutate {
    copy => { "id" => "[@metadata][_id]"}
    remove_field => ["id", "@version", "unix_ts_in_secs"]
  }
}
#logstash输出配置
output {
  # 采用stdout可以将同步数据输出到控制台，主要是调试阶段使用
  stdout { codec =>  "rubydebug"}

  # 指定输出到ES的具体索引
  elasticsearch {
      index => "rdbms_sync_idx"
      hosts => "es01:9200"
		  user => "elastic"
		  password => "sangang"
      document_id => "%{[@metadata][_id]}"
  }
}